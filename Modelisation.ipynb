{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "So_Q7iW_Haxz",
    "outputId": "8a0c216a-153e-496a-e0bb-b5135f168cd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: pyspark in /usr/local/lib/python3.9/dist-packages (3.4.0)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.9/dist-packages (from pyspark) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "HCSwIoxOHdn7"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier,DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator, RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import stddev, avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chargement du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Age: string, Attrition: string, BusinessTravel: string, DailyRate: string, Department: string, DistanceFromHome: string, Education: string, EducationField: string, EmployeeNumber: string, EnvironmentSatisfaction: string, Gender: string, HourlyRate: string, JobInvolvement: string, JobLevel: string, JobRole: string, JobSatisfaction: string, MaritalStatus: string, MonthlyIncome: string, MonthlyRate: string, NumCompaniesWorked: string, OverTime: string, PercentSalaryHike: string, PerformanceRating: string, RelationshipSatisfaction: string, StockOptionLevel: string, TotalWorkingYears: string, TrainingTimesLastYear: string, WorkLifeBalance: string, YearsAtCompany: string, YearsInCurrentRole: string, YearsSinceLastPromotion: string, YearsWithCurrManager: string]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "sw4jKGAnHeVq"
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('attrition').getOrCreate()\n",
    "file_location = \"HR-Employee-Attrition.csv\"\n",
    "file_type = \"csv\"\n",
    "# CSV options\n",
    "infer_schema = \"false\"\n",
    "first_row_is_header = \"true\"\n",
    "delimiter = \",\"\n",
    "# The applied options are for CSV files. For other file types, these will be ignored.\n",
    "df = spark.read.format(file_type) \\\n",
    ".option(\"inferSchema\", infer_schema) \\\n",
    ".option(\"header\", first_row_is_header) \\\n",
    ".option(\"sep\", delimiter) \\\n",
    ".load(file_location)\n",
    "\n",
    "df = df.drop(\"Over18\")\n",
    "df = df.drop(\"EmployeeCount\")\n",
    "df = df.drop(\"StandardHours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialisation des modèles et des paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"j'ai mis ce bloque en commentaire car si vous tester l'entrainement\\navec bcp d'hyperparamètre ca peut prendre du temps. Vous pouvez l'enlever des commentaire\\net mettre le deuxieme bloc en commentaire si vous construisez votre modèle\\n\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"j'ai mis le 1er bloque en commentaire car si vous tester l'entrainement\n",
    "avec bcp d'hyperparamètres ca peut prendre du temps. Vous pouvez lenlever des commentaire\n",
    "et mettre le deuxieme bloc en commentaire si vous construisez votre modèle\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "j4L9PB1GHgc0"
   },
   "outputs": [],
   "source": [
    "# gbt = GBTClassifier(featuresCol='features', labelCol='label')\n",
    "# param_grid_gbt = ParamGridBuilder() \\\n",
    "#     .addGrid(gbt.maxDepth, [2, 4, 6]) \\\n",
    "#     .addGrid(gbt.maxBins, [20, 30]) \\\n",
    "#     .addGrid(gbt.maxIter, [10, 20, 30]) \\\n",
    "#     .build()\n",
    "\n",
    "# rf = RandomForestClassifier(featuresCol='features', labelCol='label')\n",
    "# param_grid_rf = ParamGridBuilder() \\\n",
    "#     .addGrid(rf.maxDepth, [2, 5, 10]) \\\n",
    "#     .addGrid(rf.maxBins, [10, 20, 30]) \\\n",
    "#     .addGrid(rf.numTrees, [10, 50, 100]) \\\n",
    "#     .addGrid(rf.impurity, ['gini', 'entropy']) \\\n",
    "#     .build()\n",
    "\n",
    "# lr = LogisticRegression(featuresCol='features', labelCol='label')\n",
    "# param_grid_lr = ParamGridBuilder() \\\n",
    "#     .addGrid(lr.regParam, [0.01, 0.05, 0.1]) \\\n",
    "#     .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "#     .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt = GBTClassifier(featuresCol='features', labelCol='label')\n",
    "param_grid_gbt = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxDepth, [2]) \\\n",
    "    .addGrid(gbt.maxBins, [20]) \\\n",
    "    .addGrid(gbt.maxIter, [10]) \\\n",
    "    .build()\n",
    "\n",
    "rf = RandomForestClassifier(featuresCol='features', labelCol='label')\n",
    "param_grid_rf = ParamGridBuilder() \\\n",
    "    .addGrid(rf.maxDepth, [2]) \\\n",
    "    .addGrid(rf.maxBins, [10]) \\\n",
    "    .addGrid(rf.numTrees, [10]) \\\n",
    "    .addGrid(rf.impurity, ['gini']) \\\n",
    "    .build()\n",
    "\n",
    "lr = LogisticRegression(featuresCol='features', labelCol='label')\n",
    "param_grid_lr = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.01]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.0]) \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "TzzJCt2UHh0a"
   },
   "outputs": [],
   "source": [
    "def convert_to_int(df):\n",
    "    # convertir les colonnes string en double quand cela est possible\n",
    "    for column in df.columns:\n",
    "        try:\n",
    "            if int(df.select(column).first()[0]):\n",
    "                df = df.withColumn(column, col(column).cast(\"double\"))\n",
    "        except:\n",
    "            pass\n",
    "    return df\n",
    "        \n",
    "def remove_outliers(df):\n",
    "\n",
    "    # Boucle pour enlever les valeurs aberrantes de chaque colonne\n",
    "    for col in df.columns:\n",
    "        # Calcul des statistiques pour la colonne\n",
    "        stats = df.select(avg(col), stddev(col)).first()\n",
    "        mean = stats[0]\n",
    "        std = stats[1]  \n",
    "        if mean is not None and std is not None:\n",
    "            # Calcul du seuil pour déterminer les valeurs aberrantes\n",
    "            threshold = 3 * std + mean     \n",
    "            # Suppression des valeurs aberrantes pour la colonne\n",
    "            df = df.filter(df[col] <= threshold)\n",
    "    return df\n",
    "\n",
    "\n",
    "def assembler_for_pipeline(df, label):\n",
    "    categoricalColumns = [col for (col, dtype) in df.dtypes if dtype == \"string\" and col != label]\n",
    "    stages = []\n",
    "\n",
    "    for categoricalCol in categoricalColumns:\n",
    "        stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + 'Index')\n",
    "        encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n",
    "        stages += [stringIndexer, encoder]\n",
    "    \n",
    "    label_stringIdx = StringIndexer(inputCol=label, outputCol=\"label\")\n",
    "    stages += [label_stringIdx]\n",
    "\n",
    "    numericCols = [col for (col, dtype) in df.dtypes if dtype.startswith('double') and col != \"label\"]\n",
    "    assemblerInputs = [c + \"classVec\" for c in categoricalColumns] + numericCols\n",
    "    assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "    return assembler, stages\n",
    "\n",
    "def model_for_pipeline(classifier, param_grid):\n",
    "    evaluator = BinaryClassificationEvaluator(labelCol='label')\n",
    "    cv = CrossValidator(estimator=classifier, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=3).setSeed(1234)\n",
    "    return cv\n",
    "\n",
    "def view_feature_importances(df):\n",
    "    \n",
    "    assembler, stages = assembler_for_pipeline(df, 'Attrition')\n",
    "    rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "    paramGrid = ParamGridBuilder() \\\n",
    "        .addGrid(rf.numTrees, [10, 20]) \\\n",
    "        .addGrid(rf.maxDepth, [5, 10]) \\\n",
    "        .build()\n",
    "    \n",
    "    evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "    train, test = df.randomSplit([0.8, 0.2])\n",
    "    stages += [assembler, rf]\n",
    "    pipeline = Pipeline(stages=stages)\n",
    "    \n",
    "    pipelineModel = pipeline.fit(df)\n",
    "    predictions = pipelineModel.transform(df)\n",
    "    auc = evaluator.evaluate(predictions)\n",
    "    print(\"AUC-ROC = %g\" % auc)\n",
    "    \n",
    "    importances = pipelineModel.stages[-1].featureImportances.toArray()\n",
    "    cols = df.columns\n",
    "    selectedcols = [\"label\", \"features\"] + cols\n",
    "    cols_importances = list(zip(selectedcols, importances))\n",
    "    sorted_cols_importances = sorted(cols_importances, key=lambda x: x[1], reverse=True)\n",
    "    print(\"Colonnes triées par ordre d'importance décroissante :\")\n",
    "    for col, importance in sorted_cols_importances:\n",
    "        print(col, \"=\", importance)\n",
    "        \n",
    "    return sorted_cols_importances\n",
    "        \n",
    "def pipelinedata(df, assembler, stages, model):\n",
    "    \n",
    "    stages += [assembler, model]\n",
    "    train, test = df.randomSplit([0.8, 0.2])\n",
    "    pipeline = Pipeline(stages=stages)\n",
    "    pipelineModel = pipeline.fit(train)\n",
    "    predictions = pipelineModel.transform(test)\n",
    "    predictions.take(1)\n",
    "    selected = predictions.select(\"label\", \"prediction\", \"rawPrediction\", \"probability\")\n",
    "    display(selected)\n",
    "    return model, predictions, selected\n",
    "\n",
    "def metrics(predictions, model):\n",
    "\n",
    "    evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
    "    auc_roc = evaluator.evaluate(predictions)\n",
    "    evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"accuracy\")\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"rmse\")\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "    print(model + \": courbe ROC = %g\" % auc_roc)\n",
    "    print(model + \": précision = %g\" % accuracy)\n",
    "    print(model + \": RMSE = %g\" % rmse)\n",
    "\n",
    "    return accuracy\n",
    "    \n",
    "def filter_most_important_columns(df, sorted_cols_importances, label):\n",
    "    selected_cols = [col for col, importance in sorted_cols_importances if importance > 0.01]\n",
    "    if label not in selected_cols:\n",
    "        selected_cols.append(label)\n",
    "    if \"features\" in selected_cols:\n",
    "        selected_cols.remove(\"features\")\n",
    "    if \"label\" in selected_cols:\n",
    "        selected_cols.remove(\"label\")\n",
    "    df = df.select(selected_cols)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART1 . ANALYSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nettoyage du dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "jGXlEqb8Hi8_"
   },
   "outputs": [],
   "source": [
    "df = convert_to_int(df)\n",
    "df = remove_outliers(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## voir les champs les plus importants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BYzsIR3UHl8h",
    "outputId": "c124dbe7-d6c2-4339-a846-45edd8cefe73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC = 0.919119\n",
      "Colonnes triées par ordre d'importance décroissante :\n",
      "MonthlyRate = 0.0983397388908216\n",
      "NumCompaniesWorked = 0.03756839918566912\n",
      "MonthlyIncome = 0.03746662993664787\n",
      "features = 0.02484224106688456\n",
      "JobLevel = 0.014621880098258258\n",
      "OverTime = 0.01434072393497946\n",
      "Attrition = 0.011603479972813755\n",
      "DistanceFromHome = 0.010027570527431829\n",
      "YearsWithCurrManager = 0.009372115765421535\n",
      "MaritalStatus = 0.009059242489480389\n",
      "YearsInCurrentRole = 0.008896542439843457\n",
      "PerformanceRating = 0.006405850536698984\n",
      "EmployeeNumber = 0.0063590962155242615\n",
      "TotalWorkingYears = 0.0057390272753579845\n",
      "label = 0.005246639765268216\n",
      "PercentSalaryHike = 0.004550331139239345\n",
      "HourlyRate = 0.004333128155377987\n",
      "Gender = 0.004055819560471669\n",
      "DailyRate = 0.003562612347840823\n",
      "Age = 0.0034841170066732276\n",
      "EducationField = 0.003354173937055974\n",
      "Department = 0.0033048991277145985\n",
      "YearsSinceLastPromotion = 0.003200894872720736\n",
      "EnvironmentSatisfaction = 0.0030973149737195996\n",
      "YearsAtCompany = 0.0028187770209029558\n",
      "JobInvolvement = 0.001816001044206359\n",
      "Education = 0.0016154209317761521\n",
      "JobSatisfaction = 0.0015143758398603994\n",
      "JobRole = 0.001126974230151956\n",
      "TrainingTimesLastYear = 0.0010835214076065265\n",
      "BusinessTravel = 0.0\n",
      "RelationshipSatisfaction = 0.0\n",
      "StockOptionLevel = 0.0\n",
      "WorkLifeBalance = 0.0\n"
     ]
    }
   ],
   "source": [
    "sorted_cols_importances = view_feature_importances(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filtrer df pour ne garder que les champs retenus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "n6WRWhW-Hnzc"
   },
   "outputs": [],
   "source": [
    "df_most_important = filter_most_important_columns(df, sorted_cols_importances, 'Attrition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZofVRyvZJhU-",
    "outputId": "37f1e5f3-01ef-4830-d7d4-0077f7c11ba8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+-------------+--------+--------+---------+----------------+\n",
      "|MonthlyRate|NumCompaniesWorked|MonthlyIncome|JobLevel|OverTime|Attrition|DistanceFromHome|\n",
      "+-----------+------------------+-------------+--------+--------+---------+----------------+\n",
      "|    19479.0|               8.0|       5993.0|     2.0|     Yes|      Yes|             1.0|\n",
      "|    24907.0|               1.0|       5130.0|     2.0|      No|       No|             8.0|\n",
      "|     2396.0|               6.0|       2090.0|     1.0|     Yes|      Yes|             2.0|\n",
      "|    23159.0|               1.0|       2909.0|     1.0|     Yes|       No|             3.0|\n",
      "|    16632.0|               9.0|       3468.0|     1.0|      No|       No|             2.0|\n",
      "|    11864.0|               0.0|       3068.0|     1.0|      No|       No|             2.0|\n",
      "|     9964.0|               4.0|       2670.0|     1.0|     Yes|       No|             3.0|\n",
      "|    13335.0|               1.0|       2693.0|     1.0|      No|       No|            24.0|\n",
      "|     8787.0|               0.0|       9526.0|     3.0|      No|       No|            23.0|\n",
      "|    16577.0|               6.0|       5237.0|     2.0|      No|       No|            27.0|\n",
      "+-----------+------------------+-------------+--------+--------+---------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_most_important.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tout ce qui vient avant \"DEMARRAGE DU TRAIN\" devra rester dans la partie analyse et non pas dans le train\\npuisque si au niveau de l\\'analyse les colonnes les plus importantes changent, notre interface ne fonctionnera plus.\\nil faut garder une cohérence entre notre dataset et les champs du html\\nIl faut donc que le dataset reste statique\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Tout ce qui vient avant \"DEMARRAGE DU TRAIN\" devra rester dans la partie analyse et non pas dans le train\n",
    "puisque si au niveau de l'analyse les colonnes les plus importantes changent, notre interface ne fonctionnera plus.\n",
    "il faut garder une cohérence entre notre dataset et les champs du html\n",
    "Il faut donc que le dataset reste statique\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART2. DEMARRAGE DU TRAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## entrainement du modèle et selectionner le meilleur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "md9ujDMhmpvX"
   },
   "outputs": [],
   "source": [
    "def select_most_efficient_model(df):\n",
    "\n",
    "    best_model = None\n",
    "    best_accuracy = 0\n",
    "    models = {}\n",
    "    \n",
    "    df = convert_to_int(df)\n",
    "    df = remove_outliers(df)\n",
    "    # je selectionne les colonnes de manières brut pour qu'elles ne se modifie pas\n",
    "    df_most_important = df.select(['MonthlyRate', 'NumCompaniesWorked', 'MonthlyIncome', 'JobLevel', 'OverTime', 'Attrition', 'DistanceFromHome'])\n",
    "\n",
    "    df_gbt = df_most_important\n",
    "    df_rf = df_most_important\n",
    "    df_lr = df_most_important\n",
    "\n",
    "    # model random forest\n",
    "    assembler, stages = assembler_for_pipeline(df_rf, 'Attrition')\n",
    "    model_rf = model_for_pipeline(rf, param_grid_rf)\n",
    "    model_rf, predictions_rf, selected_rf = pipelinedata(df_rf, assembler, stages, model_rf)\n",
    "    accuracy = metrics(predictions_rf, 'rf')\n",
    "    models[\"rf\"] = {\"model\" : model_rf, \"accuracy\": accuracy}\n",
    "\n",
    "\n",
    "    # model gradient boosting\n",
    "    assembler, stages = assembler_for_pipeline(df_gbt, 'Attrition')\n",
    "    model_gbt = model_for_pipeline(gbt, param_grid_gbt)\n",
    "    model_gbt, predictions_gbt, selected_gbt = pipelinedata(df_gbt, assembler, stages, model_gbt)\n",
    "    accuracy = metrics(predictions_gbt, 'gbt')\n",
    "    models[\"gbt\"] = {\"model\" : model_gbt, \"accuracy\": accuracy}\n",
    "\n",
    "    # model logistic regression\n",
    "    assembler, stages = assembler_for_pipeline(df_lr, 'Attrition')\n",
    "    model_lr = model_for_pipeline(lr, param_grid_lr)\n",
    "    model_lr, predictions_lr, selected_lr = pipelinedata(df_lr, assembler, stages, model_lr)\n",
    "    accuracy = metrics(predictions_lr, 'lr')\n",
    "    models[\"lr\"] = {\"model\" : model_lr, \"accuracy\": accuracy}\n",
    "\n",
    "    for model_name, model_info in models.items():\n",
    "        accuracy = model_info['accuracy']\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model = model_info['model']\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "TM83AwxEq701",
    "outputId": "3f585d3d-8cf6-4924-9965-0a34cf0dfe8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: double, prediction: double, rawPrediction: vector, probability: vector]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf: courbe ROC = 0.746821\n",
      "rf: précision = 0.826667\n",
      "rf: RMSE = 0.416333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[label: double, prediction: double, rawPrediction: vector, probability: vector]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbt: courbe ROC = 0.758846\n",
      "gbt: précision = 0.845324\n",
      "gbt: RMSE = 0.393289\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[label: double, prediction: double, rawPrediction: vector, probability: vector]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: courbe ROC = 0.781599\n",
      "lr: précision = 0.834586\n",
      "lr: RMSE = 0.406711\n"
     ]
    }
   ],
   "source": [
    "model = select_most_efficient_model(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sauvegarde et enregistrement du zip (commande à utiliser sur Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossValidator_f3fdd3f62418"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "tWRzZWmaHuY_"
   },
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# model.save(\"Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "nufiNTaGHwgz",
    "outputId": "e10d1d78-a3bc-4783-ca4f-e49a1f40ef1c"
   },
   "outputs": [],
   "source": [
    "# shutil.make_archive('Model', 'zip','Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZiJP3beUPBVB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
